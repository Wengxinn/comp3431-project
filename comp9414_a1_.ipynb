{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "750b0a0c",
   "metadata": {},
   "source": [
    "# COMP9414 Assignment 1\n",
    "# Artificial Neural Networks\n",
    "@author: Weng Xinn Chow (z5346077)\n",
    "\n",
    "@date: 21st June 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dd09e6",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea4225fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "import keras\n",
    "import keras_tuner as kt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import Adam, SGD\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from keras_tuner import HyperModel\n",
    "from keras_tuner.tuners import RandomSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b851511b",
   "metadata": {},
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99ab08b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"./AirQualityUCI _ Students.xlsx\"\n",
    "df = pd.read_excel(filepath)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320a9fe5",
   "metadata": {},
   "source": [
    "### Initial data inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58062ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check shape of dataframe\n",
    "# print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f9d313e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe862685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44ce244",
   "metadata": {},
   "source": [
    "### Initial data cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bb9f295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates (if any)\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d29148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values (-200) with NaN\n",
    "df.replace(-200, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d9304cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dad0ac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d41bd18",
   "metadata": {},
   "source": [
    "## Initial Exploratory data analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3d5657",
   "metadata": {},
   "source": [
    "### Statistical summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7fb2fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Range (min & max), mean, std deviation of variables\n",
    "# df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9793ee",
   "metadata": {},
   "source": [
    "Statistical data such as min, max and mean can be observed from the summary above. The range of variables are distributed widely, indicating the potential need of feature normalisation before training models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ed6857",
   "metadata": {},
   "source": [
    "### Missing data visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb4d7163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Heatmap to visualise missing data\n",
    "# plt.figure(figsize=(12,6))\n",
    "\n",
    "# # Determine if values are null (True if null)\n",
    "# missing_df = df.isnull()\n",
    "# sns.heatmap(missing_df, cbar=False, cmap='rocket_r')\n",
    "\n",
    "# plt.title('Missing Data Heatmap')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c830bb9a",
   "metadata": {},
   "source": [
    "The heatmap is used to visualise missing data across each variable. It can be observed that NMHC(GT) has the largest amount of missing values compared to other variables. The effect of missing data is not negligible and therefore, it may be infeasible to drop those values for our model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14071d6b",
   "metadata": {},
   "source": [
    "### Distribution of target variables: CO(GT) & NOx(GT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fd9063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_distribution(data, columns, nrows, ncols, figsize, bins=100, kde=True, dpi=100, titles=None, suptitle=None, xlabels=None):\n",
    "#     \"\"\"\n",
    "#     Plot respective distribution of specified columns.\n",
    "#     \"\"\"\n",
    "#     fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize, dpi=dpi)\n",
    "#     axes = axes.flatten()\n",
    "    \n",
    "#     # Plot distribution for each feature\n",
    "#     for i, col in enumerate(columns):\n",
    "#         sns.histplot(data[col], bins=bins, kde=kde, ax=axes[i])\n",
    "#         axes[i].set_title(f\"Distribution of {col}\")\n",
    "#         axes[i].set_xlabel(col)\n",
    "#         axes[i].set_ylabel(\"Frequency\")\n",
    "        \n",
    "#     plt.tight_layout()\n",
    "#     return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19101c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Distribution plots of CO(GT) and NOx(GT)\n",
    "# target_cols = [\"CO(GT)\", \"NOx(GT)\"]\n",
    "# target_df = df[target_cols]\n",
    "# fig, axes = plot_distribution(data=target_df, columns=target_cols, nrows=1, ncols=2, figsize=(18,6))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70244398",
   "metadata": {},
   "source": [
    "The plots above show the distribution of respective target variables for classification and regression tasks (excluding missing values)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770a12d8",
   "metadata": {},
   "source": [
    "### Distribution of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0862f85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "\n",
    "# Merge Datetime (datetime object)\n",
    "df2['DateTime'] = pd.to_datetime(df2['Date'].astype(str) + ' ' + df2['Time'].astype(str))\n",
    "df2.insert(1, 'DateTime', df2.pop('DateTime'))\n",
    "\n",
    "# Drop Date and Time column\n",
    "df2.drop(['Date', 'Time'], axis=1, inplace=True)\n",
    "# df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8965026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "984d2ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_cols = [col for col in df2.columns if col != \"CO(GT)\" and col != \"NOx(GT)\"]\n",
    "# print(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4576c80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot distribution of features\n",
    "# feature_df = df2[feature_cols]\n",
    "# fig, axes = plot_distribution(data=feature_df, columns=feature_cols, nrows=4, ncols=3, figsize=(16,12))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a485f3",
   "metadata": {},
   "source": [
    "From the plots above, it can be clearly seen that the distributions of NMHC(GT), C6H6(GT), PT08.S3(NOx) are positively skewed. By analysing the distribution plots, it helps to determine the reasonable methods to handle missing values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6b954e",
   "metadata": {},
   "source": [
    "## Data preprocessing & EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7009a3",
   "metadata": {},
   "source": [
    "### Handling outliers and missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a019168e",
   "metadata": {},
   "source": [
    "By considering the amount of missing data, it is infeasible to directly drop those values as they could contribute a significant effects towards the final output of the model. **Mean and median imputation** and **data interpolation** are used to handle the missing values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b9de95",
   "metadata": {},
   "source": [
    "#### Mean and median imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48c2074",
   "metadata": {},
   "source": [
    "As mentioned before, each variable have different skewness of distribution. Therefore, imputation of missing values are carried out based on their distribution skewness. If a feature has a normal (symmetric) distribution, mean imputation (replace missing values with mean) can be used. On the other hand, if it has a skewed distribution, it is generally more appropriate to use median imputation as median is more robust to potential outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d2a6817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Threshold to determine skewness threshold\n",
    "# # Normal distribution if skewness < threshold\n",
    "# threshold = 0.5\n",
    "# df2_impute = df2.copy()\n",
    "# for col in df2_impute.drop(\"DateTime\", axis=1):\n",
    "#     skewness = df2_impute[col].skew()\n",
    "#     mean = df2_impute[col].mean()\n",
    "#     median = df2_impute[col].median()\n",
    "    \n",
    "#     # Mean imputation if normal distribution\n",
    "#     if abs(skewness) < threshold: \n",
    "#         df2_impute[col].fillna(mean, inplace=True)\n",
    "#     # Median imputation if skewed distribution\n",
    "#     else:\n",
    "#         df2_impute[col].fillna(median, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6ded9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2_impute.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e7a0575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2_impute.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "701fb2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2_impute.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df77fafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Distribution plots of CO(GT) and NO2(GT)\n",
    "# # target_cols = [\"CO(GT)\", \"NOx(GT)\"]\n",
    "# target_df = df2_impute[target_cols]\n",
    "# fig, axes = plot_distribution(data=target_df, columns=target_cols, nrows=1, ncols=2, figsize=(18,6))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39b75d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot distribution of features\n",
    "# feature_df = df2_impute[feature_cols]\n",
    "# fig, axes = plot_distribution(data=feature_df, columns=feature_cols, nrows=4, ncols=3, figsize=(16,12))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836276e8",
   "metadata": {},
   "source": [
    "From the plots, it can be observed that the mean and median for corresponding variables has higher frequency, which is understandable as they are imputed to replace the missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedf920c",
   "metadata": {},
   "source": [
    "#### Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669d18ab",
   "metadata": {},
   "source": [
    "The dataset is recorded over intervals of time. Therefore, it is pertinent to use time data interpolation to fill the missing data. The method basically estimates the missing data based on the two adjacent data values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45de87ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_interpolate = df2.copy()\n",
    "\n",
    "# Set DateTime as index for interpolation\n",
    "df2_interpolate.set_index('DateTime', inplace=True)\n",
    "df2_interpolate.interpolate(method='time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc2bd645",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_interpolate.reset_index(inplace=True)\n",
    "# df2_interpolate.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f46140e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2_interpolate.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ac338cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2_interpolate.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06239455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Distribution plots of CO(GT) and NOx(GT)\n",
    "# # target_cols = [\"CO(GT)\", \"NO2(GT)\"]\n",
    "# target_df = df2_interpolate[target_cols]\n",
    "# fig, axes = plot_distribution(data=target_df, columns=target_cols, nrows=1, ncols=2, figsize=(18,6))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55a4aa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot distribution of features\n",
    "# feature_df = df2_interpolate[feature_cols]\n",
    "# fig, axes = plot_distribution(data=feature_df, columns=feature_cols, nrows=4, ncols=3, figsize=(16,12))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a2849d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the interpolated data\n",
    "# Drop DateTime (not continuous data)\n",
    "df_ = df2_interpolate.copy()\n",
    "df_.drop(\"DateTime\", axis=1, inplace=True)\n",
    "\n",
    "# # Use the imputed data\n",
    "# # Drop DateTime (not continuous data)\n",
    "# df_ = df2_impute.copy()\n",
    "# df_.drop(\"DateTime\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5c7a75",
   "metadata": {},
   "source": [
    "By comparing the results of two methods, data interpolation is used to handle missing values. Imputation is not suitable for time-series data and the result indicates potential bias towards mean and median values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2a1c44",
   "metadata": {},
   "source": [
    "### Correlation between features and target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4cbf8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(18,6), dpi=100)\n",
    "# axes = axes.flatten()\n",
    "\n",
    "# # Correlation of CO(GT)\n",
    "# sns.heatmap(df_.corr().drop(\"CO(GT)\")[[\"CO(GT)\"]], cmap=\"coolwarm\", annot=True, ax=axes[0]) \n",
    "# axes[0].set_title(\"Correlation between CO(GT) and other variables\")\n",
    "\n",
    "# # Correlation of NOx(GT)\n",
    "# sns.heatmap(df_.corr().drop(\"NOx(GT)\")[[\"NOx(GT)\"]], cmap=\"coolwarm\", annot=True, ax=axes[1]) \n",
    "# axes[1].set_title(\"Correlation between NOx(GT) and other variables\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713a013f",
   "metadata": {},
   "source": [
    "Correlation between features and target variables are plotted in the heatmaps above. They are useful for feature selection, in which those features with lower correlation can be treated as redundant data, can be removed from model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252ef23b",
   "metadata": {},
   "source": [
    "### Feature selection with random forests and correlation-filtering approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9b9153",
   "metadata": {},
   "source": [
    "A hybrid of correlation-filtering approach and random forest model (to determine feature importance) are used to select feature. By assigning a correlation threshold and an importance threshold, we can select features effectively based on their correlation with the corresponding target variable and their importance value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d162a7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data used to train\n",
    "# df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b164d8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(task, df, corr_threshold=0.1, perm_threshold=0.01, random_state=42, test_size=0.3, n_estimators=100, max_depth=None):\n",
    "    \"\"\"\n",
    "    Feature selection using the hybrid approach of correlation filtering and Random forest model. \n",
    "    Selected features should satisfy both threshold conditions.\n",
    "    \"\"\"\n",
    "    # Classification task\n",
    "    if task == 1:\n",
    "        target = \"CO(GT)\"\n",
    "    # Regression task\n",
    "    else: target = \"NOx(GT)\"\n",
    "    \n",
    "    # Split train and test sets\n",
    "    X = df.drop(target, axis=1)\n",
    "    y = df[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=random_state, test_size=test_size)\n",
    "    \n",
    "    # Normalise data\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Train a random forest regressor\n",
    "    rf = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=random_state)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    # Get permutation importance of each feature \n",
    "    importances = permutation_importance(rf, X_test, y_test, random_state=42)\n",
    "    \n",
    "    # Create a relevant dataframe and sort by descending order\n",
    "    feature_importances = pd.DataFrame({\n",
    "        \"feature\": X.columns,\n",
    "        \"importance\": importances.importances_mean\n",
    "    }).sort_values(by=\"importance\", ascending=False)\n",
    "    \n",
    "    print(\"Feature permutation importances:\")\n",
    "    print(feature_importances)\n",
    "    \n",
    "    # Compute correlation between features and the target variable and create dataframe\n",
    "    corr = df.corr()[target].drop(target)\n",
    "    feature_corr = corr.to_frame().reset_index()\n",
    "    feature_corr.columns = [\"feature\", \"correlation\"]\n",
    "    \n",
    "    print(f\"\\nFeature correlations with {target}:\")\n",
    "    print(feature_corr)\n",
    "    \n",
    "    # Select features that exceed correlation threshold\n",
    "    corr_features = corr[corr.abs() > corr_threshold].index.tolist()\n",
    "    \n",
    "    # Select features that exceed permutation importance threshold\n",
    "    perm_features = X.columns[importances.importances_mean > perm_threshold]\n",
    "    \n",
    "    # Filter out features that don't exceed both threshold\n",
    "    selected_features = list(set(corr_features).union(set(perm_features)))\n",
    "    \n",
    "    return feature_importances, feature_corr, selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba4cbcb",
   "metadata": {},
   "source": [
    "#### Classification task: CO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "169957fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for feature selection\n",
    "corr_threshold = 0.1\n",
    "perm_threshold = 0.01\n",
    "test_size = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd031b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature permutation importances:\n",
      "          feature  importance\n",
      "4         NOx(GT)    0.685849\n",
      "3   PT08.S2(NMHC)    0.127466\n",
      "7    PT08.S4(NO2)    0.089900\n",
      "2        C6H6(GT)    0.067200\n",
      "6         NO2(GT)    0.067147\n",
      "0     PT08.S1(CO)    0.045799\n",
      "11             AH    0.029536\n",
      "8     PT08.S5(O3)    0.013575\n",
      "1        NMHC(GT)    0.010562\n",
      "9               T    0.009245\n",
      "5    PT08.S3(NOx)    0.008634\n",
      "10             RH    0.005370\n",
      "\n",
      "Feature correlations with CO(GT):\n",
      "          feature  correlation\n",
      "0     PT08.S1(CO)     0.787535\n",
      "1        NMHC(GT)     0.277825\n",
      "2        C6H6(GT)     0.805365\n",
      "3   PT08.S2(NMHC)     0.797853\n",
      "4         NOx(GT)     0.790965\n",
      "5    PT08.S3(NOx)    -0.661838\n",
      "6         NO2(GT)     0.676904\n",
      "7    PT08.S4(NO2)     0.549297\n",
      "8     PT08.S5(O3)     0.767356\n",
      "9               T     0.028419\n",
      "10             RH     0.063494\n",
      "11             AH     0.079203\n"
     ]
    }
   ],
   "source": [
    "# Select features based on Random forests and correlation with CO(GT)\n",
    "importances1, corr1, selected1 = feature_selection(task=1, \n",
    "                                                  df=df_,\n",
    "                                                  corr_threshold=corr_threshold, \n",
    "                                                  perm_threshold=perm_threshold, \n",
    "                                                  test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4507a392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot importances and correlations\n",
    "# fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(18,6), dpi=100)\n",
    "# axes = axes.flatten()\n",
    "\n",
    "# sns.barplot(x=\"importance\", y=\"feature\", data=importances1, ax=axes[0])\n",
    "# axes[0].set_title(\"Feature permutation importances\")\n",
    "\n",
    "# # Observe absolute values and sort by descending order\n",
    "# corr1[\"correlation\"] = corr1[\"correlation\"].abs()\n",
    "# corr1 = corr1.sort_values(by=\"correlation\", ascending=False)\n",
    "# sns.barplot(x=\"correlation\", y=\"feature\", data=corr1, ax=axes[1])\n",
    "# axes[1].set_title(\"Feature correlations with CO(GT)\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ebf0ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features for task 1:\n",
      "['AH', 'NO2(GT)', 'PT08.S4(NO2)', 'C6H6(GT)', 'PT08.S2(NMHC)', 'PT08.S3(NOx)', 'NOx(GT)', 'NMHC(GT)', 'PT08.S5(O3)', 'PT08.S1(CO)']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Selected features for task 1:\\n{selected1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3476345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data with selected features only\n",
    "df_1 = df_.loc[:, selected1 + [\"CO(GT)\"]]\n",
    "# df_1.head()\n",
    "\n",
    "# df_1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2a63c9",
   "metadata": {},
   "source": [
    "Feature: T and RH are weakly correlated with the target, CO(GT) and their importance values computed from random forests model are considered low (as they didn't exceed the threshold), so they are eliminated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5c6cb6",
   "metadata": {},
   "source": [
    "#### Regression task: NOx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a933025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature permutation importances:\n",
      "          feature  importance\n",
      "6         NO2(GT)    0.342008\n",
      "5    PT08.S3(NOx)    0.205525\n",
      "0          CO(GT)    0.138101\n",
      "7    PT08.S4(NO2)    0.124562\n",
      "9               T    0.047846\n",
      "10             RH    0.032111\n",
      "8     PT08.S5(O3)    0.026172\n",
      "3        C6H6(GT)    0.013430\n",
      "4   PT08.S2(NMHC)    0.009544\n",
      "11             AH    0.008629\n",
      "1     PT08.S1(CO)    0.007015\n",
      "2        NMHC(GT)    0.002810\n",
      "\n",
      "Feature correlations with NOx(GT):\n",
      "          feature  correlation\n",
      "0          CO(GT)     0.790965\n",
      "1     PT08.S1(CO)     0.672578\n",
      "2        NMHC(GT)     0.163453\n",
      "3        C6H6(GT)     0.647824\n",
      "4   PT08.S2(NMHC)     0.640303\n",
      "5    PT08.S3(NOx)    -0.636793\n",
      "6         NO2(GT)     0.768611\n",
      "7    PT08.S4(NO2)     0.202550\n",
      "8     PT08.S5(O3)     0.737645\n",
      "9               T    -0.246834\n",
      "10             RH     0.204182\n",
      "11             AH    -0.127588\n"
     ]
    }
   ],
   "source": [
    "# Select features based on Random forests and correlation with NOx(GT)\n",
    "importances2, corr2, selected2 = feature_selection(task=2, \n",
    "                                                  df=df_,\n",
    "                                                  corr_threshold=corr_threshold, \n",
    "                                                  perm_threshold=perm_threshold, \n",
    "                                                  test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "898bd9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot importances and correlations\n",
    "# fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(18,6), dpi=100)\n",
    "# axes = axes.flatten()\n",
    "\n",
    "# sns.barplot(x=\"importance\", y=\"feature\", data=importances2, ax=axes[0])\n",
    "# axes[0].set_title(\"Feature permutation importances\")\n",
    "\n",
    "# # Observe absolute values and sort by descending order\n",
    "# corr2[\"correlation\"] = corr2[\"correlation\"].abs()\n",
    "# corr2 = corr2.sort_values(by=\"correlation\", ascending=False)\n",
    "# sns.barplot(x=\"correlation\", y=\"feature\", data=corr2, ax=axes[1])\n",
    "# axes[1].set_title(\"Feature correlations with NOx(GT)\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8a7e45d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features for task 2:\n",
      "['C6H6(GT)', 'CO(GT)', 'AH', 'PT08.S2(NMHC)', 'NMHC(GT)', 'PT08.S5(O3)', 'T', 'NO2(GT)', 'PT08.S4(NO2)', 'PT08.S3(NOx)', 'RH', 'PT08.S1(CO)']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Selected features for task 2:\\n{selected2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0baaa697",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_.loc[:, selected2 + [\"NOx(GT)\"]]\n",
    "# df_2.head()\n",
    "\n",
    "# df_2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e3d88c",
   "metadata": {},
   "source": [
    "No features are eliminated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea9ae28",
   "metadata": {},
   "source": [
    "### Target label for classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ebeb66c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine threshold by calculating the mean of CO(GT)\n",
    "mean_threshold = df[\"CO(GT)\"].mean()\n",
    "\n",
    "# Label target: 1 if > threshold, 0 otherwise\n",
    "df_1[\"target\"] = (df_1[\"CO(GT)\"] > mean_threshold).astype(int) \n",
    "df_1.drop(\"CO(GT)\", axis=1, inplace=True)\n",
    "# df_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdedd58e",
   "metadata": {},
   "source": [
    "### Distribution of processed target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fe64223b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change column name of target for regression task (consistency)\n",
    "df_2.rename(columns={\"NOx(GT)\": \"target\"}, inplace=True)\n",
    "# df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "040a301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot distribution of target variables after data preprocessing for \n",
    "# fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(18,6), dpi=100)\n",
    "# axes = axes.flatten()\n",
    "\n",
    "# # Data label for classification task\n",
    "# sns.countplot(x=\"target\", data=df_1, ax=axes[0])\n",
    "# axes[0].set_title(\"Distribution of target label: CO2(GT) > mean threshold\")\n",
    "# axes[0].set_xlabel(\"CO2(GT) > mean threshold\")\n",
    "# axes[0].set_ylabel(\"Frequency\")\n",
    "\n",
    "# # Target data for regression task\n",
    "# sns.histplot(df_2[\"target\"], bins=100, kde=True, ax=axes[1])\n",
    "# axes[1].set_title(f\"Distribution of NOx(GT)\")\n",
    "# axes[1].set_xlabel(\"NOx(GT)\")\n",
    "# axes[1].set_ylabel(\"Frequency\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be049186",
   "metadata": {},
   "source": [
    "### Data normalisation & train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8de7d249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalised_train_test_split(task, df, test_size=0.2, random_state=0):\n",
    "    \"\"\"\n",
    "    Normalise the given data and split into train, validation and test sets according to the specified test size proportion.\n",
    "    \"\"\"\n",
    "    # Split data into X (features) and y (target)\n",
    "    X = df.drop(\"target\", axis=1)\n",
    "    y = df[\"target\"]\n",
    "    print(f\"Shape of X, y: {X.shape}, {y.shape}\")\n",
    "    \n",
    "    # Normalise features\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    # Task 1 split\n",
    "    # Split train, validation, test sets\n",
    "    if task == 1:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=test_size, random_state=random_state)\n",
    "    # Task 2 split\n",
    "    else: \n",
    "        train_size = int((1 - (test_size)) * len(df))\n",
    "        val_size = int(test_size * train_size)\n",
    "        # Validation set comes from the partitioned train split\n",
    "        train_size -= val_size\n",
    "        test_size = int(test_size * len(df))\n",
    "        \n",
    "        X_train = X[:train_size]\n",
    "        y_train = y[:train_size]\n",
    "        X_val = X[train_size:train_size+val_size]\n",
    "        y_val = y[train_size:train_size+val_size]\n",
    "        X_test = X[train_size+val_size:]\n",
    "        y_test = y[train_size+val_size:]\n",
    "        \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8b615e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for normalisation and train test split\n",
    "test_size=0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c77a4f9",
   "metadata": {},
   "source": [
    "#### Classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7a12da4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X, y: (8358, 10), (8358,)\n"
     ]
    }
   ],
   "source": [
    "# Classification data\n",
    "X_train1, X_val1, X_test1, y_train1, y_val1, y_test1 = normalised_train_test_split(task=1, df=df_1, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "52edca96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (5348, 10), (5348,)\n",
      "Validation set shape: (1338, 10), (1338,)\n",
      "Test set shape: (1672, 10), (1672,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train set shape: {X_train1.shape}, {y_train1.shape}\")\n",
    "print(f\"Validation set shape: {X_val1.shape}, {y_val1.shape}\")\n",
    "print(f\"Test set shape: {X_test1.shape}, {y_test1.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53255b3f",
   "metadata": {},
   "source": [
    "#### Regression task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "00d3114a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X, y: (8358, 12), (8358,)\n"
     ]
    }
   ],
   "source": [
    "# Regression data\n",
    "X_train2, X_val2, X_test2, y_train2, y_val2, y_test2 = normalised_train_test_split(task=2, df=df_2, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6dfc8630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (5349, 12), (5349,)\n",
      "Validation set shape: (1337, 12), (1337,)\n",
      "Test set shape: (1672, 12), (1672,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train set shape: {X_train2.shape}, {y_train2.shape}\")\n",
    "print(f\"Validation set shape: {X_val2.shape}, {y_val2.shape}\")\n",
    "print(f\"Test set shape: {X_test2.shape}, {y_test2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f78cdb",
   "metadata": {},
   "source": [
    "## Classification task with neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04481e71",
   "metadata": {},
   "source": [
    "### Design of neural network (Baseline classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a8d2d376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(input_shape, num_layers, num_units, activations, loss, metrics, optimizer=\"adam\", dropout_rate=None):\n",
    "    \"\"\"\n",
    "    Define the nueral network according to the specified input dimension, number of layers, number of units per layer, \n",
    "    activation functions across each layer, loss function and metrics, optimisers across each layer and dropout rate.\n",
    "    \"\"\"\n",
    "    # Define a sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add layers to the model\n",
    "    # Number of layers does not include input layer\n",
    "    for i in range(num_layers): \n",
    "        # Output layer\n",
    "        if i == num_layers - 1:\n",
    "            model.add(Dense(1, activation=activations[\"output\"]))\n",
    "        # First hidden layer\n",
    "        elif i == 0:\n",
    "            model.add(Dense(num_units, input_shape=input_shape, activation=activations[\"hidden\"]))\n",
    "            num_units //= 2\n",
    "            # Apply dropout for regularisation\n",
    "            if dropout_rate is not None:\n",
    "                model.add(Drop(rate=dropout_level))\n",
    "        # Subsequent hidden layers\n",
    "        else:\n",
    "            model.add(Dense(num_units, activation=activations[\"hidden\"]))\n",
    "            num_units //= 2\n",
    "            # Apply dropout for regularisation\n",
    "            if dropout_rate is not None:\n",
    "                model.add(Drop(rate=dropout_level))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4025d042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for baseline classifier\n",
    "num_layers1 = 3\n",
    "num_units1 = 16\n",
    "activations1 = {\"hidden\": \"relu\", \"output\": \"sigmoid\"}\n",
    "loss1 = \"binary_crossentropy\"\n",
    "# optimizer1 = \"sgd\"\n",
    "optimizer1 = \"adam\"\n",
    "metrics1 = [\"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "da142a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train the baseline classifier\n",
    "# baseline_classifier = define_model(input_shape=(X_train1.shape[1],),\n",
    "#                                    num_layers=num_layers1, \n",
    "#                                    num_units=num_units1, \n",
    "#                                    activations=activations1,\n",
    "#                                    loss=loss1, \n",
    "#                                    optimizer=optimizer1, \n",
    "#                                    metrics=metrics1)\n",
    "\n",
    "# Set training parameters\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "\n",
    "# # Train the model\n",
    "# baseline_classifier.fit(X_train1, y_train1, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4387e309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a712f6",
   "metadata": {},
   "source": [
    "### Hyperparameter-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1edbbf",
   "metadata": {},
   "source": [
    "Parameters for neural network training including number of units per hidden layer, and optimiser (SGD, Adam) are tuned using a neural network based on the designed baseline model, which has 1 input layer, 2 hidden layers and 1 output layer. The tuned model is trained on 100 epochs, with batch size of 16. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "359bb7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_model(hp, params, input_shape, activations, loss, metrics):\n",
    "    \"\"\" \n",
    "    Define the neural network (1 input layer, 2 hidden layers and 1 output layer) for hyperparameter-tuning.\n",
    "    \"\"\"\n",
    "    # Define a sequential model\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # Define number of units for the first hidden layer\n",
    "    num_units_first_hidden_layer = hp.Choice(\"num_units\", params[\"num_units\"])\n",
    "    \n",
    "    # Add first hidden layer\n",
    "    model.add(Dense(units=num_units_first_hidden_layer, \n",
    "                    input_shape=input_shape, \n",
    "                    activation=activations[\"hidden\"]))\n",
    "    \n",
    "    # Add second hidden layer\n",
    "    model.add(Dense(units=num_units_first_hidden_layer // 2, \n",
    "                    input_shape=input_shape, \n",
    "                    activation=activations[\"hidden\"]))\n",
    "    \n",
    "    # Add output layer\n",
    "    model.add(Dense(1, activation=activations[\"output\"]))\n",
    "    # Compile the model\n",
    "    \n",
    "    model.compile(optimizer=hp.Choice(\"optimizer\", params[\"optimizer\"]), loss=loss, metrics=metrics)\n",
    "    return model\n",
    "\n",
    "def build_hp_model1(hp):\n",
    "    \"\"\"\n",
    "    Build hyperparameter-tuning classifier (task 1).\n",
    "    \"\"\"\n",
    "    # Specified input shape\n",
    "    input_shape = (X_train1.shape[1],)\n",
    "\n",
    "    # Hyperparameters to be tuned\n",
    "    params = {\n",
    "        \"num_units\": [16, 32], \n",
    "        \"optimizer\": [\"adam\", \"sgd\"],\n",
    "    }\n",
    "    \n",
    "    # Set fixed model training parameters\n",
    "    activations = {\"hidden\": \"relu\", \"output\": \"sigmoid\"}\n",
    "    loss = \"binary_crossentropy\"\n",
    "    metrics = [\"accuracy\"]\n",
    "    \n",
    "    return hp_model(hp, params, input_shape, activations, loss, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "46719bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tuning(task, max_trials=5, executions_per_trial=3, epochs=50, validation_split=0.2):\n",
    "    \"\"\"\n",
    "    Tune hyperparameters for the defined neural network.\n",
    "    \"\"\"\n",
    "    if task == 1:\n",
    "        hypermodel = build_hp_model1\n",
    "        X_train = X_train1\n",
    "        y_train = y_train1\n",
    "    else: \n",
    "        hypermodel = build_hp_model2\n",
    "        X_train = X_train1\n",
    "        y_train = y_train1\n",
    "        \n",
    "    # Tune with random search\n",
    "    rs = RandomSearch(hypermodel=build_hp_model1,\n",
    "                      objective=\"val_accuracy\",\n",
    "                      max_trials=max_trials, # max total number of trials\n",
    "                      executions_per_trial=executions_per_trial,\n",
    "                      directory=\"hp_dir\",\n",
    "                      project_name=f\"t{task}_hp\")\n",
    "    \n",
    "    batch_size = 16\n",
    "    # Hyperparameter tuning using keras tuner random search\n",
    "    rs.search(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=validation_split)\n",
    "    \n",
    "    # Get the optimal hyperparameters\n",
    "    best_hps=rs.get_best_hyperparameters(num_trials=1)[0]\n",
    "    \n",
    "    return best_hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "423a1228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from hp_dir\\t1_hp\\tuner0.json\n",
      "32\n",
      "adam\n"
     ]
    }
   ],
   "source": [
    "# Tune number of units per layer and optimiser\n",
    "best_hps1 = hyperparameter_tuning(task=1)\n",
    "\n",
    "print(best_hps1.get(\"num_units\"))\n",
    "print(best_hps1.get(\"optimizer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34dd6ff",
   "metadata": {},
   "source": [
    "### Model training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "113d4792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X_train, y_train, X_val, y_val, num_layers, num_units, activations, loss, optimizer, metrics, epochs, \\\n",
    "                   batch_size):\n",
    "    \"\"\"\n",
    "    Train and evaluate the neural network\n",
    "    \"\"\"\n",
    "    # Define neural network and train the model\n",
    "    model = define_model(input_shape=(X_train.shape[1],), \n",
    "                         num_layers=num_layers, \n",
    "                         num_units=num_units, \n",
    "                         activations=activations,\n",
    "                         loss=loss, \n",
    "                         optimizer=optimizer, \n",
    "                         metrics=metrics)\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=epochs, validation_data=(X_val, y_val))\n",
    "    \n",
    "    # Evaluate the model\n",
    "    train_result = model.evaluate(X_train, y_train)\n",
    "    val_result = model.evaluate(X_val, y_val)\n",
    "    \n",
    "    return model, history, train_result, val_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c117f00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wengx\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6361 - loss: 0.5897 - val_accuracy: 0.8677 - val_loss: 0.3058\n",
      "Epoch 2/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8904 - loss: 0.2752 - val_accuracy: 0.8864 - val_loss: 0.2704\n",
      "Epoch 3/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9040 - loss: 0.2468 - val_accuracy: 0.8924 - val_loss: 0.2609\n",
      "Epoch 4/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9060 - loss: 0.2464 - val_accuracy: 0.8961 - val_loss: 0.2556\n",
      "Epoch 5/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9029 - loss: 0.2477 - val_accuracy: 0.9021 - val_loss: 0.2510\n",
      "Epoch 6/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9099 - loss: 0.2252 - val_accuracy: 0.9036 - val_loss: 0.2466\n",
      "Epoch 7/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9117 - loss: 0.2275 - val_accuracy: 0.9013 - val_loss: 0.2458\n",
      "Epoch 8/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.2296 - val_accuracy: 0.9043 - val_loss: 0.2439\n",
      "Epoch 9/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9088 - loss: 0.2400 - val_accuracy: 0.9028 - val_loss: 0.2397\n",
      "Epoch 10/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9174 - loss: 0.2231 - val_accuracy: 0.9043 - val_loss: 0.2397\n",
      "Epoch 11/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9158 - loss: 0.2269 - val_accuracy: 0.9073 - val_loss: 0.2386\n",
      "Epoch 12/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9158 - loss: 0.2223 - val_accuracy: 0.9073 - val_loss: 0.2395\n",
      "Epoch 13/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9184 - loss: 0.2144 - val_accuracy: 0.9088 - val_loss: 0.2356\n",
      "Epoch 14/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9193 - loss: 0.2192 - val_accuracy: 0.9058 - val_loss: 0.2335\n",
      "Epoch 15/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.2170 - val_accuracy: 0.9066 - val_loss: 0.2328\n",
      "Epoch 16/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9182 - loss: 0.2083 - val_accuracy: 0.9111 - val_loss: 0.2308\n",
      "Epoch 17/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9183 - loss: 0.2150 - val_accuracy: 0.9133 - val_loss: 0.2339\n",
      "Epoch 18/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9240 - loss: 0.2044 - val_accuracy: 0.9096 - val_loss: 0.2309\n",
      "Epoch 19/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9212 - loss: 0.2044 - val_accuracy: 0.9148 - val_loss: 0.2302\n",
      "Epoch 20/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9249 - loss: 0.2052 - val_accuracy: 0.9126 - val_loss: 0.2284\n",
      "Epoch 21/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9244 - loss: 0.1958 - val_accuracy: 0.9111 - val_loss: 0.2285\n",
      "Epoch 22/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9204 - loss: 0.2085 - val_accuracy: 0.9103 - val_loss: 0.2293\n",
      "Epoch 23/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9228 - loss: 0.2016 - val_accuracy: 0.9058 - val_loss: 0.2267\n",
      "Epoch 24/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9205 - loss: 0.2043 - val_accuracy: 0.9066 - val_loss: 0.2258\n",
      "Epoch 25/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9222 - loss: 0.2021 - val_accuracy: 0.9066 - val_loss: 0.2352\n",
      "Epoch 26/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9158 - loss: 0.2046 - val_accuracy: 0.9126 - val_loss: 0.2259\n",
      "Epoch 27/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9243 - loss: 0.1938 - val_accuracy: 0.9111 - val_loss: 0.2252\n",
      "Epoch 28/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9192 - loss: 0.2068 - val_accuracy: 0.9096 - val_loss: 0.2263\n",
      "Epoch 29/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9241 - loss: 0.1875 - val_accuracy: 0.9066 - val_loss: 0.2248\n",
      "Epoch 30/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9196 - loss: 0.1936 - val_accuracy: 0.9111 - val_loss: 0.2250\n",
      "Epoch 31/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9226 - loss: 0.1965 - val_accuracy: 0.9073 - val_loss: 0.2270\n",
      "Epoch 32/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9208 - loss: 0.1936 - val_accuracy: 0.9103 - val_loss: 0.2266\n",
      "Epoch 33/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9260 - loss: 0.1923 - val_accuracy: 0.9066 - val_loss: 0.2260\n",
      "Epoch 34/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9231 - loss: 0.1931 - val_accuracy: 0.9111 - val_loss: 0.2253\n",
      "Epoch 35/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9322 - loss: 0.1763 - val_accuracy: 0.9073 - val_loss: 0.2268\n",
      "Epoch 36/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9231 - loss: 0.1945 - val_accuracy: 0.9066 - val_loss: 0.2236\n",
      "Epoch 37/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9272 - loss: 0.1928 - val_accuracy: 0.9081 - val_loss: 0.2238\n",
      "Epoch 38/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9332 - loss: 0.1766 - val_accuracy: 0.9073 - val_loss: 0.2238\n",
      "Epoch 39/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9233 - loss: 0.1887 - val_accuracy: 0.9073 - val_loss: 0.2280\n",
      "Epoch 40/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9252 - loss: 0.1859 - val_accuracy: 0.9096 - val_loss: 0.2229\n",
      "Epoch 41/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9235 - loss: 0.1854 - val_accuracy: 0.9073 - val_loss: 0.2224\n",
      "Epoch 42/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9289 - loss: 0.1820 - val_accuracy: 0.9036 - val_loss: 0.2244\n",
      "Epoch 43/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9275 - loss: 0.1841 - val_accuracy: 0.9096 - val_loss: 0.2227\n",
      "Epoch 44/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9239 - loss: 0.1914 - val_accuracy: 0.9073 - val_loss: 0.2250\n",
      "Epoch 45/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9265 - loss: 0.1806 - val_accuracy: 0.9073 - val_loss: 0.2282\n",
      "Epoch 46/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9251 - loss: 0.1874 - val_accuracy: 0.9043 - val_loss: 0.2248\n",
      "Epoch 47/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9225 - loss: 0.1958 - val_accuracy: 0.9073 - val_loss: 0.2221\n",
      "Epoch 48/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9302 - loss: 0.1771 - val_accuracy: 0.9066 - val_loss: 0.2220\n",
      "Epoch 49/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9266 - loss: 0.1840 - val_accuracy: 0.9066 - val_loss: 0.2266\n",
      "Epoch 50/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9300 - loss: 0.1749 - val_accuracy: 0.9088 - val_loss: 0.2224\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9258 - loss: 0.1797 - val_accuracy: 0.9066 - val_loss: 0.2209\n",
      "Epoch 52/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9243 - loss: 0.1853 - val_accuracy: 0.9103 - val_loss: 0.2210\n",
      "Epoch 53/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9327 - loss: 0.1710 - val_accuracy: 0.9096 - val_loss: 0.2235\n",
      "Epoch 54/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9293 - loss: 0.1808 - val_accuracy: 0.9081 - val_loss: 0.2223\n",
      "Epoch 55/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9263 - loss: 0.1799 - val_accuracy: 0.9081 - val_loss: 0.2193\n",
      "Epoch 56/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9316 - loss: 0.1717 - val_accuracy: 0.9088 - val_loss: 0.2216\n",
      "Epoch 57/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9298 - loss: 0.1717 - val_accuracy: 0.9096 - val_loss: 0.2222\n",
      "Epoch 58/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9319 - loss: 0.1703 - val_accuracy: 0.9081 - val_loss: 0.2202\n",
      "Epoch 59/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9289 - loss: 0.1788 - val_accuracy: 0.9088 - val_loss: 0.2239\n",
      "Epoch 60/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9291 - loss: 0.1813 - val_accuracy: 0.9111 - val_loss: 0.2210\n",
      "Epoch 61/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9298 - loss: 0.1820 - val_accuracy: 0.9096 - val_loss: 0.2205\n",
      "Epoch 62/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9281 - loss: 0.1805 - val_accuracy: 0.9111 - val_loss: 0.2250\n",
      "Epoch 63/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9256 - loss: 0.1891 - val_accuracy: 0.9066 - val_loss: 0.2251\n",
      "Epoch 64/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9230 - loss: 0.1882 - val_accuracy: 0.9088 - val_loss: 0.2280\n",
      "Epoch 65/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9266 - loss: 0.1888 - val_accuracy: 0.9118 - val_loss: 0.2308\n",
      "Epoch 66/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9212 - loss: 0.1869 - val_accuracy: 0.9103 - val_loss: 0.2233\n",
      "Epoch 67/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9326 - loss: 0.1666 - val_accuracy: 0.9096 - val_loss: 0.2284\n",
      "Epoch 68/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9252 - loss: 0.1886 - val_accuracy: 0.9073 - val_loss: 0.2317\n",
      "Epoch 69/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9307 - loss: 0.1754 - val_accuracy: 0.9111 - val_loss: 0.2207\n",
      "Epoch 70/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9354 - loss: 0.1712 - val_accuracy: 0.9081 - val_loss: 0.2265\n",
      "Epoch 71/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9298 - loss: 0.1813 - val_accuracy: 0.9118 - val_loss: 0.2204\n",
      "Epoch 72/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9327 - loss: 0.1782 - val_accuracy: 0.9103 - val_loss: 0.2216\n",
      "Epoch 73/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9304 - loss: 0.1736 - val_accuracy: 0.9096 - val_loss: 0.2235\n",
      "Epoch 74/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9194 - loss: 0.1906 - val_accuracy: 0.9126 - val_loss: 0.2236\n",
      "Epoch 75/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9282 - loss: 0.1821 - val_accuracy: 0.9088 - val_loss: 0.2233\n",
      "Epoch 76/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9373 - loss: 0.1652 - val_accuracy: 0.9103 - val_loss: 0.2247\n",
      "Epoch 77/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9349 - loss: 0.1668 - val_accuracy: 0.9081 - val_loss: 0.2205\n",
      "Epoch 78/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9314 - loss: 0.1743 - val_accuracy: 0.9103 - val_loss: 0.2216\n",
      "Epoch 79/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9369 - loss: 0.1687 - val_accuracy: 0.9126 - val_loss: 0.2211\n",
      "Epoch 80/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9310 - loss: 0.1706 - val_accuracy: 0.9126 - val_loss: 0.2218\n",
      "Epoch 81/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9343 - loss: 0.1697 - val_accuracy: 0.9111 - val_loss: 0.2277\n",
      "Epoch 82/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9346 - loss: 0.1701 - val_accuracy: 0.9096 - val_loss: 0.2217\n",
      "Epoch 83/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9310 - loss: 0.1768 - val_accuracy: 0.9096 - val_loss: 0.2258\n",
      "Epoch 84/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9295 - loss: 0.1824 - val_accuracy: 0.9133 - val_loss: 0.2270\n",
      "Epoch 85/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9425 - loss: 0.1541 - val_accuracy: 0.9088 - val_loss: 0.2268\n",
      "Epoch 86/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9360 - loss: 0.1678 - val_accuracy: 0.9066 - val_loss: 0.2224\n",
      "Epoch 87/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9279 - loss: 0.1772 - val_accuracy: 0.9058 - val_loss: 0.2236\n",
      "Epoch 88/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9305 - loss: 0.1747 - val_accuracy: 0.9111 - val_loss: 0.2232\n",
      "Epoch 89/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9325 - loss: 0.1770 - val_accuracy: 0.9103 - val_loss: 0.2230\n",
      "Epoch 90/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9317 - loss: 0.1703 - val_accuracy: 0.9133 - val_loss: 0.2235\n",
      "Epoch 91/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9312 - loss: 0.1706 - val_accuracy: 0.9103 - val_loss: 0.2249\n",
      "Epoch 92/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9335 - loss: 0.1680 - val_accuracy: 0.9096 - val_loss: 0.2288\n",
      "Epoch 93/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9329 - loss: 0.1671 - val_accuracy: 0.9141 - val_loss: 0.2243\n",
      "Epoch 94/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9323 - loss: 0.1772 - val_accuracy: 0.9103 - val_loss: 0.2300\n",
      "Epoch 95/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9367 - loss: 0.1656 - val_accuracy: 0.9133 - val_loss: 0.2253\n",
      "Epoch 96/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9374 - loss: 0.1654 - val_accuracy: 0.9103 - val_loss: 0.2244\n",
      "Epoch 97/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9377 - loss: 0.1612 - val_accuracy: 0.9133 - val_loss: 0.2244\n",
      "Epoch 98/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9395 - loss: 0.1636 - val_accuracy: 0.9088 - val_loss: 0.2286\n",
      "Epoch 99/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9310 - loss: 0.1680 - val_accuracy: 0.9081 - val_loss: 0.2217\n",
      "Epoch 100/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9321 - loss: 0.1743 - val_accuracy: 0.9081 - val_loss: 0.2274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9375 - loss: 0.1651\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.2093\n"
     ]
    }
   ],
   "source": [
    "# Train and validate the model using tuned parameters\n",
    "# Minus 2 to fulfil the condition: # parameters < (# samples / 10) - prevent overfitting\n",
    "num_units1 = best_hps1.get(\"num_units\") - 2\n",
    "optimizer1 = best_hps1.get(\"optimizer\")\n",
    "\n",
    "model1, history1, train_result1, val_result1 = evaluate_model(X_train=X_train1, \n",
    "                                                            y_train=y_train1, \n",
    "                                                            X_val=X_val1, \n",
    "                                                            y_val=y_val1, \n",
    "                                                            num_layers=num_layers1, \n",
    "                                                            num_units=num_units1, \n",
    "                                                            activations=activations1,\n",
    "                                                            loss=loss1, \n",
    "                                                            optimizer=optimizer1, \n",
    "                                                            metrics=metrics1,\n",
    "                                                            epochs=epochs, \n",
    "                                                            batch_size=batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "95c4de54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9371727705001831\n",
      "Validation accuracy: 0.908071756362915\n"
     ]
    }
   ],
   "source": [
    "_, train_acc1 = train_result1\n",
    "_, val_acc1 = val_result1\n",
    "\n",
    "print(f\"Train accuracy: {train_acc1}\")\n",
    "print(f\"Validation accuracy: {val_acc1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0ba12286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">465</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                  │             \u001b[38;5;34m330\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │             \u001b[38;5;34m465\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m16\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,435</span> (9.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,435\u001b[0m (9.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">811</span> (3.17 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m811\u001b[0m (3.17 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,624</span> (6.35 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,624\u001b[0m (6.35 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0712b529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot loss and accuracy during training\n",
    "# plt.figure(figsize=(18,6), dpi=100)\n",
    "\n",
    "# # Plot loss for training and validation\n",
    "# plt.subplot(121)\n",
    "# plt.title(\"Classification task - Loss\")\n",
    "# plt.xlabel(\"Epoch\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "\n",
    "# plt.plot(history1.history[\"loss\"], label=\"Training loss\")\n",
    "# plt.plot(history1.history[\"val_loss\"], label=\"Validation loss\")\n",
    "# plt.legend()\n",
    "\n",
    "# # Plot accuracy for training and validation\n",
    "# plt.subplot(122)\n",
    "# plt.title(\"Classification task - Accuracy\")\n",
    "# plt.xlabel(\"Epoch\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "\n",
    "# plt.plot(history1.history[\"accuracy\"], label=\"Training accuracy\")\n",
    "# plt.plot(history1.history[\"val_accuracy\"], label=\"Validation accuracy\")\n",
    "# plt.legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90984ede",
   "metadata": {},
   "source": [
    "### Model testing and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e9d0ec",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "abfea647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True positives</th>\n",
       "      <th>False negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False positives</th>\n",
       "      <td>929</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True negatives</th>\n",
       "      <td>55</td>\n",
       "      <td>616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 True positives  False negatives\n",
       "False positives             929               72\n",
       "True negatives               55              616"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict label\n",
    "y_pred1 = (model1.predict(X_test1)> 0.5).astype(\"int32\").flatten()\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm1 = confusion_matrix(y_test1, y_pred1)\n",
    "\n",
    "# Convert into dataframe\n",
    "indices = [\"False positives\", \"True negatives\"]\n",
    "columns = [\"True positives\", \"False negatives\"]\n",
    "cm1 = pd.DataFrame(cm1, columns=columns, index=indices)\n",
    "cm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1402d2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8,5), dpi=100)\n",
    "sns.heatmap(cm1, annot=True, cmap='Blues', fmt='g', cbar=False)\n",
    "plt.xlabel('Predicted values')\n",
    "plt.ylabel('True values')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740d9682",
   "metadata": {},
   "source": [
    "#### Precision and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ae65f21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Number of Samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CO(GT) classification</th>\n",
       "      <td>0.924043</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>1672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Accuracy  Precision  Number of Samples\n",
       "CO(GT) classification  0.924043   0.918033               1672"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision: tp/(tp+fp)\n",
    "# Precision: Evaluate how many predicted values are labelled correctly\n",
    "precision1 = precision_score(y_pred1, y_test1)\n",
    "\n",
    "# Accuracy\n",
    "accuracy1 = accuracy_score(y_pred1, y_test1)\n",
    "\n",
    "# Number of samples\n",
    "num_samples1 = len(y_test1)\n",
    "\n",
    "acc_pc = pd.DataFrame({\n",
    "    \"Accuracy\": accuracy1, \n",
    "    \"Precision\": precision1, \n",
    "    \"Number of Samples\": num_samples1\n",
    "}, index=[\"CO(GT) classification\"])\n",
    "acc_pc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6269f52e",
   "metadata": {},
   "source": [
    "## Regression task with neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42ca0be",
   "metadata": {},
   "source": [
    "### Design of neural network (Baseline regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2849ebff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for baseline classifier\n",
    "num_layers2 = 3\n",
    "num_units2 = 16\n",
    "activations2 = {\"hidden\": \"relu\", \"output\": \"linear\"}\n",
    "loss2 = \"mean_squared_error\"\n",
    "# optimizer2 = \"sgd\"\n",
    "optimizer2 = \"adam\"\n",
    "metrics2 = [\"mae\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "18f314ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_regressor = define_model(input_shape=(X_train2.shape[1],),\n",
    "#                                    num_layers=num_layers2, \n",
    "#                                    num_units=num_units2, \n",
    "#                                    activations=activations2,\n",
    "#                                    loss=loss2, \n",
    "#                                    optimizer=optimizer2, \n",
    "#                                    metrics=metrics2)\n",
    "\n",
    "# # Train the model\n",
    "# baseline_regressor.fit(X_train2, y_train2, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "10d7bbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_regressor.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b817c0",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e2ea8b",
   "metadata": {},
   "source": [
    "Parameters for neural network training including number of units per hidden layer, and optimiser (SGD, Adam) are tuned using a neural network based on the designed baseline model, which has 1 input layer, 2 hidden layers and 1 output layer. The tuned model is trained on 100 epochs, with batch size of 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9722192b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hp_model2(hp):\n",
    "    \"\"\"\n",
    "    Build hyperparameter-tuning regressor (task 2).\n",
    "    \"\"\"\n",
    "    # Specified input shape\n",
    "    input_shape = (X_train2.shape[1],)\n",
    "\n",
    "    # Hyperparameters to be tuned\n",
    "    params = {\n",
    "        \"num_units\": [16, 32], \n",
    "        \"optimizer\": [\"adam\", \"sgd\"],\n",
    "    }\n",
    "    \n",
    "    # Set fixed model training parameters\n",
    "    activations = {\"hidden\": \"relu\", \"output\": \"linear\"}\n",
    "    loss = \"mean_squared_error\"\n",
    "    metrics = [\"mae\"]\n",
    "    \n",
    "    return hp_model(hp, params, input_shape, activations, loss, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d997ac00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from hp_dir\\t2_hp\\tuner0.json\n",
      "32\n",
      "adam\n"
     ]
    }
   ],
   "source": [
    "# Tune number of units per layer and optimiser\n",
    "best_hps2 = hyperparameter_tuning(task=2)\n",
    "\n",
    "print(best_hps2.get(\"num_units\"))\n",
    "print(best_hps2.get(\"optimizer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eff8a5b",
   "metadata": {},
   "source": [
    "### Model training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0a61a965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wengx\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 54234.9258 - mae: 177.7900 - val_loss: 210792.8281 - val_mae: 379.2927\n",
      "Epoch 2/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 40231.0430 - mae: 146.0432 - val_loss: 132959.6719 - val_mae: 306.6071\n",
      "Epoch 3/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16368.6494 - mae: 90.2930 - val_loss: 95038.0156 - val_mae: 261.1535\n",
      "Epoch 4/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12973.1445 - mae: 82.2238 - val_loss: 82697.2422 - val_mae: 240.5994\n",
      "Epoch 5/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 10412.4766 - mae: 74.7993 - val_loss: 64999.4297 - val_mae: 209.5857\n",
      "Epoch 6/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 9127.5771 - mae: 69.1251 - val_loss: 48656.1992 - val_mae: 175.1418\n",
      "Epoch 7/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7043.6426 - mae: 60.1293 - val_loss: 35389.9609 - val_mae: 141.6362\n",
      "Epoch 8/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5544.8428 - mae: 53.5925 - val_loss: 24823.1445 - val_mae: 112.0196\n",
      "Epoch 9/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4685.4253 - mae: 49.1088 - val_loss: 19584.9453 - val_mae: 96.8433\n",
      "Epoch 10/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4219.4341 - mae: 46.7083 - val_loss: 16018.8604 - val_mae: 87.8403\n",
      "Epoch 11/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4035.5991 - mae: 45.0082 - val_loss: 15009.9121 - val_mae: 87.0711\n",
      "Epoch 12/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3738.4111 - mae: 43.3979 - val_loss: 14577.9375 - val_mae: 87.7223\n",
      "Epoch 13/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3532.8269 - mae: 42.2007 - val_loss: 14756.7969 - val_mae: 90.5949\n",
      "Epoch 14/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3396.5220 - mae: 41.6595 - val_loss: 14345.5859 - val_mae: 91.8124\n",
      "Epoch 15/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3234.5845 - mae: 40.9326 - val_loss: 14274.9023 - val_mae: 93.6243\n",
      "Epoch 16/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3180.9150 - mae: 40.5272 - val_loss: 14287.4365 - val_mae: 95.7210\n",
      "Epoch 17/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3146.6504 - mae: 40.0332 - val_loss: 14962.3848 - val_mae: 98.1942\n",
      "Epoch 18/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3262.4490 - mae: 40.8089 - val_loss: 15724.7002 - val_mae: 100.6809\n",
      "Epoch 19/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3097.9895 - mae: 40.0469 - val_loss: 15339.8447 - val_mae: 101.3112\n",
      "Epoch 20/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3085.5623 - mae: 39.6924 - val_loss: 15729.6143 - val_mae: 103.1809\n",
      "Epoch 21/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3029.4983 - mae: 39.4466 - val_loss: 16379.5840 - val_mae: 105.3109\n",
      "Epoch 22/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3060.9990 - mae: 39.4884 - val_loss: 16426.9551 - val_mae: 105.7536\n",
      "Epoch 23/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2960.0532 - mae: 38.6814 - val_loss: 16424.2227 - val_mae: 106.8602\n",
      "Epoch 24/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2981.6411 - mae: 38.6312 - val_loss: 16203.5352 - val_mae: 106.4875\n",
      "Epoch 25/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2981.7180 - mae: 38.5929 - val_loss: 16354.8193 - val_mae: 107.6426\n",
      "Epoch 26/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2778.5896 - mae: 37.2673 - val_loss: 16646.5410 - val_mae: 108.6670\n",
      "Epoch 27/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2887.9875 - mae: 38.1823 - val_loss: 17086.2617 - val_mae: 109.5190\n",
      "Epoch 28/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2729.1282 - mae: 37.2682 - val_loss: 17039.0898 - val_mae: 109.0228\n",
      "Epoch 29/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2837.2969 - mae: 38.0549 - val_loss: 17185.8398 - val_mae: 111.1148\n",
      "Epoch 30/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2718.0188 - mae: 37.0307 - val_loss: 17438.8477 - val_mae: 111.2395\n",
      "Epoch 31/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2785.8137 - mae: 37.3923 - val_loss: 17423.2344 - val_mae: 111.1082\n",
      "Epoch 32/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2770.5408 - mae: 36.4799 - val_loss: 17193.4297 - val_mae: 111.7357\n",
      "Epoch 33/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2681.9866 - mae: 36.1010 - val_loss: 17366.3848 - val_mae: 111.5343\n",
      "Epoch 34/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2925.6509 - mae: 37.3056 - val_loss: 17293.6641 - val_mae: 111.7018\n",
      "Epoch 35/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2727.7700 - mae: 36.8353 - val_loss: 17791.5352 - val_mae: 113.8453\n",
      "Epoch 36/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2562.3940 - mae: 35.9098 - val_loss: 17726.4082 - val_mae: 112.2270\n",
      "Epoch 37/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2718.0022 - mae: 36.7653 - val_loss: 17677.8574 - val_mae: 113.0408\n",
      "Epoch 38/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2662.3584 - mae: 36.3902 - val_loss: 17761.4355 - val_mae: 113.2079\n",
      "Epoch 39/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2664.3877 - mae: 35.4084 - val_loss: 18371.4668 - val_mae: 115.4414\n",
      "Epoch 40/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2610.5112 - mae: 35.5093 - val_loss: 18245.8652 - val_mae: 114.5896\n",
      "Epoch 41/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2660.2354 - mae: 35.8344 - val_loss: 18062.2656 - val_mae: 114.8139\n",
      "Epoch 42/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2582.5596 - mae: 35.9015 - val_loss: 18315.9180 - val_mae: 115.4154\n",
      "Epoch 43/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2532.8813 - mae: 34.9180 - val_loss: 18564.7402 - val_mae: 116.2317\n",
      "Epoch 44/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2798.5039 - mae: 36.2426 - val_loss: 18134.7207 - val_mae: 115.1333\n",
      "Epoch 45/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2546.3098 - mae: 35.0899 - val_loss: 18629.8105 - val_mae: 116.1282\n",
      "Epoch 46/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2622.9233 - mae: 35.6517 - val_loss: 18152.4082 - val_mae: 114.5094\n",
      "Epoch 47/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2540.6350 - mae: 34.3925 - val_loss: 18502.5508 - val_mae: 116.4538\n",
      "Epoch 48/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2599.0830 - mae: 35.4013 - val_loss: 17699.1191 - val_mae: 113.2729\n",
      "Epoch 49/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2682.2708 - mae: 35.7881 - val_loss: 17936.0840 - val_mae: 114.5897\n",
      "Epoch 50/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2612.0383 - mae: 35.6205 - val_loss: 18593.6191 - val_mae: 115.9720\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2540.7393 - mae: 34.8264 - val_loss: 18543.4629 - val_mae: 115.8401\n",
      "Epoch 52/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2518.7148 - mae: 34.4340 - val_loss: 18429.1406 - val_mae: 116.4621\n",
      "Epoch 53/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2417.5264 - mae: 33.5728 - val_loss: 18634.0156 - val_mae: 117.0574\n",
      "Epoch 54/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2591.7412 - mae: 34.8846 - val_loss: 18347.5332 - val_mae: 116.0679\n",
      "Epoch 55/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2470.5408 - mae: 34.4962 - val_loss: 18542.2461 - val_mae: 116.1893\n",
      "Epoch 56/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2406.9844 - mae: 33.9077 - val_loss: 18299.4219 - val_mae: 115.4680\n",
      "Epoch 57/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2329.8281 - mae: 33.5252 - val_loss: 19019.4023 - val_mae: 117.6817\n",
      "Epoch 58/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2439.9360 - mae: 33.9490 - val_loss: 18749.9766 - val_mae: 117.0255\n",
      "Epoch 59/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2338.0483 - mae: 33.3498 - val_loss: 18922.9883 - val_mae: 118.1312\n",
      "Epoch 60/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2490.4031 - mae: 34.6305 - val_loss: 18220.0059 - val_mae: 114.6344\n",
      "Epoch 61/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2496.5215 - mae: 34.0063 - val_loss: 18354.7500 - val_mae: 115.5122\n",
      "Epoch 62/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2395.4680 - mae: 33.6407 - val_loss: 18659.4863 - val_mae: 116.6740\n",
      "Epoch 63/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2472.5378 - mae: 34.0060 - val_loss: 17841.4023 - val_mae: 113.8664\n",
      "Epoch 64/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2354.2034 - mae: 33.0092 - val_loss: 18758.6094 - val_mae: 117.0478\n",
      "Epoch 65/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2265.5398 - mae: 33.1887 - val_loss: 18552.3105 - val_mae: 116.7108\n",
      "Epoch 66/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2210.0530 - mae: 32.3584 - val_loss: 17786.0664 - val_mae: 114.1464\n",
      "Epoch 67/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2364.8896 - mae: 32.9838 - val_loss: 18022.2695 - val_mae: 115.0347\n",
      "Epoch 68/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2312.3127 - mae: 32.7714 - val_loss: 18269.2949 - val_mae: 116.2357\n",
      "Epoch 69/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2320.5210 - mae: 32.7325 - val_loss: 18406.3164 - val_mae: 115.8687\n",
      "Epoch 70/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2247.4031 - mae: 32.4786 - val_loss: 18094.0371 - val_mae: 114.7268\n",
      "Epoch 71/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2245.2649 - mae: 32.3698 - val_loss: 17938.8301 - val_mae: 114.0312\n",
      "Epoch 72/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2269.8118 - mae: 32.4149 - val_loss: 18175.2363 - val_mae: 114.9789\n",
      "Epoch 73/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2360.7300 - mae: 33.4745 - val_loss: 17763.1504 - val_mae: 114.4353\n",
      "Epoch 74/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2135.0300 - mae: 31.4436 - val_loss: 18791.7930 - val_mae: 117.3491\n",
      "Epoch 75/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2269.3169 - mae: 32.8922 - val_loss: 18077.9414 - val_mae: 115.0027\n",
      "Epoch 76/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2252.2974 - mae: 32.5590 - val_loss: 17683.6777 - val_mae: 113.4485\n",
      "Epoch 77/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2323.1597 - mae: 32.8011 - val_loss: 17882.4238 - val_mae: 114.4380\n",
      "Epoch 78/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2228.7229 - mae: 32.1602 - val_loss: 17662.8340 - val_mae: 113.5556\n",
      "Epoch 79/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2199.9351 - mae: 31.9096 - val_loss: 18101.9141 - val_mae: 115.8788\n",
      "Epoch 80/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2119.6660 - mae: 31.4981 - val_loss: 17820.1191 - val_mae: 114.2295\n",
      "Epoch 81/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2169.7378 - mae: 32.0165 - val_loss: 17823.5117 - val_mae: 114.6181\n",
      "Epoch 82/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2069.4714 - mae: 31.7383 - val_loss: 17314.7852 - val_mae: 112.4425\n",
      "Epoch 83/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2060.4409 - mae: 31.3810 - val_loss: 17591.6504 - val_mae: 113.9496\n",
      "Epoch 84/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2169.9314 - mae: 32.3723 - val_loss: 17752.2773 - val_mae: 113.5577\n",
      "Epoch 85/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2356.7764 - mae: 32.1956 - val_loss: 17346.6953 - val_mae: 112.7409\n",
      "Epoch 86/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2064.7712 - mae: 31.5174 - val_loss: 17584.0195 - val_mae: 113.8613\n",
      "Epoch 87/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2335.7185 - mae: 33.0211 - val_loss: 17369.0371 - val_mae: 113.1830\n",
      "Epoch 88/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2176.6484 - mae: 32.2430 - val_loss: 17255.4746 - val_mae: 113.0288\n",
      "Epoch 89/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2137.7112 - mae: 31.8411 - val_loss: 17376.2773 - val_mae: 112.6531\n",
      "Epoch 90/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2104.9998 - mae: 31.5359 - val_loss: 16823.3086 - val_mae: 110.2444\n",
      "Epoch 91/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2024.3196 - mae: 30.9542 - val_loss: 17057.4336 - val_mae: 111.4421\n",
      "Epoch 92/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2153.6960 - mae: 31.9745 - val_loss: 17067.5195 - val_mae: 111.8556\n",
      "Epoch 93/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2120.9683 - mae: 31.3692 - val_loss: 17121.4355 - val_mae: 111.9653\n",
      "Epoch 94/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2033.1772 - mae: 31.3739 - val_loss: 17285.4277 - val_mae: 113.3065\n",
      "Epoch 95/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2151.0933 - mae: 31.7196 - val_loss: 16983.6074 - val_mae: 111.8052\n",
      "Epoch 96/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2176.9341 - mae: 31.9202 - val_loss: 16951.3457 - val_mae: 111.2090\n",
      "Epoch 97/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2133.2244 - mae: 31.6456 - val_loss: 16664.2285 - val_mae: 110.1853\n",
      "Epoch 98/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2194.0134 - mae: 32.2113 - val_loss: 17325.9473 - val_mae: 112.7651\n",
      "Epoch 99/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2054.2383 - mae: 30.7503 - val_loss: 16739.6562 - val_mae: 110.3131\n",
      "Epoch 100/100\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2115.1843 - mae: 31.3313 - val_loss: 16969.3164 - val_mae: 112.0633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1113.2896 - mae: 22.8487\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16017.8301 - mae: 104.0527\n"
     ]
    }
   ],
   "source": [
    "# Train and validate the model using tuned parameters\n",
    "# Minus 4 to fulfil the condition: # parameters < (# samples / 10) - prevent overfitting\n",
    "num_units2 = best_hps2.get(\"num_units\") - 4\n",
    "optimizer2 = best_hps2.get(\"optimizer\")\n",
    "\n",
    "model2, history2, train_result2, val_result2 = evaluate_model(X_train=X_train2, \n",
    "                                                              y_train=y_train2, \n",
    "                                                              X_val=X_val2, \n",
    "                                                              y_val=y_val2, \n",
    "                                                              num_layers=num_layers2, \n",
    "                                                              num_units=num_units2, \n",
    "                                                              activations=activations2,\n",
    "                                                              loss=loss2, \n",
    "                                                              optimizer=optimizer2, \n",
    "                                                              metrics=metrics2,\n",
    "                                                              epochs=epochs, \n",
    "                                                              batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2624e26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MAE: 31.730012893676758\n",
      "Validation MAE: 112.06328582763672\n"
     ]
    }
   ],
   "source": [
    "_, train_mae2 = train_result2\n",
    "_, val_mae2 = val_result2\n",
    "\n",
    "print(f\"Train MAE: {train_mae2}\")\n",
    "print(f\"Validation MAE: {val_mae2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f6a64628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">364</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">406</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)                  │             \u001b[38;5;34m364\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                  │             \u001b[38;5;34m406\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m15\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,357</span> (9.21 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,357\u001b[0m (9.21 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">785</span> (3.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m785\u001b[0m (3.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,572</span> (6.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,572\u001b[0m (6.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2a079e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot loss and accuracy during training\n",
    "# plt.figure(figsize=(18,6), dpi=100)\n",
    "\n",
    "# # Plot loss for training and validation\n",
    "# plt.subplot(121)\n",
    "# plt.title(\"Regression task - Loss\")\n",
    "# plt.xlabel(\"Epoch\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "\n",
    "# plt.plot(history2.history[\"loss\"], label=\"Training loss\")\n",
    "# plt.plot(history2.history[\"val_loss\"], label=\"Validation loss\")\n",
    "# plt.legend()\n",
    "\n",
    "# # Plot accuracy for training and validation\n",
    "# plt.subplot(122)\n",
    "# plt.title(\"MLP Validation Phase - Actual vs Estimated NOx(GT) Values\")\n",
    "# plt.xlabel(\"Sample Index\")\n",
    "# plt.ylabel(\"NOx(GT) Value\")\n",
    "\n",
    "\n",
    "# # Predict target value\n",
    "# y_val_pred2 = model2.predict(X_val2).flatten()\n",
    "# # Drop index to make both validation sets consistent\n",
    "# y_val_plot2 = y_val2.reset_index(drop=True)\n",
    "\n",
    "# plt.plot(y_val_plot2, label=\"Actual\")\n",
    "# plt.plot(y_val_pred2, label=\"Predict\")\n",
    "# plt.legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79c785e",
   "metadata": {},
   "source": [
    "### Model testing and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7aa99a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Number of Samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Estimation of NOx(GT)</th>\n",
       "      <td>194.260311</td>\n",
       "      <td>176.720118</td>\n",
       "      <td>1672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             RMSE         MAE  Number of Samples\n",
       "Estimation of NOx(GT)  194.260311  176.720118               1672"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict target values on test set\n",
    "y_pred2 = model2.predict(X_test2).flatten()\n",
    "\n",
    "# mse\n",
    "mse2 = mean_squared_error(y_test2, y_pred2)\n",
    "# root mse\n",
    "rmse2 = mse2 ** 0.5\n",
    "\n",
    "# mae\n",
    "mae2 = mean_absolute_error(y_test2, y_pred2)\n",
    "\n",
    "num_samples2 = len(y_test2)\n",
    "\n",
    "rmse_mae = pd.DataFrame({\n",
    "    \"RMSE\": rmse2, \n",
    "    \"MAE\": mae2, \n",
    "    \"Number of Samples\": num_samples2\n",
    "}, index=[\"Estimation of NOx(GT)\"])\n",
    "rmse_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76700a3d",
   "metadata": {},
   "source": [
    "## Generalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be0d9cf",
   "metadata": {},
   "source": [
    "### Classification NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e1e00e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"Generalization Dataset.xlsx\"\n",
    "df = pd.read_excel(filepath)\n",
    "\n",
    "# Drop duplicates (if any)\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Replace missing values (-200) with NaN\n",
    "df.replace(-200, np.nan, inplace=True)\n",
    "\n",
    "df2 = df.copy()\n",
    "\n",
    "# Merge Datetime (datetime object)\n",
    "df2['DateTime'] = pd.to_datetime(df2['Date'].astype(str) + ' ' + df2['Time'].astype(str))\n",
    "df2.insert(1, 'DateTime', df2.pop('DateTime'))\n",
    "\n",
    "# Drop Date and Time column\n",
    "df2.drop(['Date', 'Time'], axis=1, inplace=True)\n",
    "# df2.head()\n",
    "\n",
    "df2_interpolate = df2.copy()\n",
    "\n",
    "# Set DateTime as index for interpolation\n",
    "df2_interpolate.set_index('DateTime', inplace=True)\n",
    "df2_interpolate.interpolate(method='time', inplace=True)\n",
    "df2_interpolate.reset_index(inplace=True)\n",
    "\n",
    "# Use the interpolated data\n",
    "# Drop DateTime (not continuous data)\n",
    "df_ = df2_interpolate.copy()\n",
    "df_.drop(\"DateTime\", axis=1, inplace=True)\n",
    "\n",
    "df_1 = df_.loc[:, selected1 + [\"CO(GT)\"]]\n",
    "df_2 = df_.loc[:, selected2 + [\"NOx(GT)\"]]\n",
    "\n",
    "# Label target: 1 if > threshold, 0 otherwise\n",
    "df_1[\"target\"] = (df_1[\"CO(GT)\"] > mean_threshold).astype(int) \n",
    "df_1.drop(\"CO(GT)\", axis=1, inplace=True)\n",
    "\n",
    "# Change column name of target for regression task (consistency)\n",
    "df_2.rename(columns={\"NOx(GT)\": \"target\"}, inplace=True)\n",
    "\n",
    "X_gen1 = df_1.drop(\"target\", axis=1)\n",
    "# Normalise features\n",
    "scaler = StandardScaler()\n",
    "X_gen1 = scaler.fit_transform(X_gen1)\n",
    "y_gen1 = df_1['target']\n",
    "\n",
    "X_gen2 = df_2.drop(\"target\", axis=1)\n",
    "# Normalise features\n",
    "scaler = StandardScaler()\n",
    "X_gen2 = scaler.fit_transform(X_gen2)\n",
    "y_gen2 = df_2['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "eff48000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True positives</th>\n",
       "      <th>False negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False positives</th>\n",
       "      <td>472</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True negatives</th>\n",
       "      <td>48</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 True positives  False negatives\n",
       "False positives             472               34\n",
       "True negatives               48              318"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict label\n",
    "y_pred1 = (model1.predict(X_gen1)> 0.5).astype(\"int32\").flatten()\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm1 = confusion_matrix(y_gen1, y_pred1)\n",
    "\n",
    "# Convert into dataframe\n",
    "indices = [\"False positives\", \"True negatives\"]\n",
    "columns = [\"True positives\", \"False negatives\"]\n",
    "cm1 = pd.DataFrame(cm1, columns=columns, index=indices)\n",
    "cm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a445798a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Number of Samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CO(GT) classification</th>\n",
       "      <td>0.905963</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Accuracy  Precision  Number of Samples\n",
       "CO(GT) classification  0.905963   0.868852                872"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision: tp/(tp+fp)\n",
    "# Precision: Evaluate how many predicted values are labelled correctly\n",
    "precision1 = precision_score(y_pred1, y_gen1)\n",
    "\n",
    "# Accuracy\n",
    "accuracy1 = accuracy_score(y_pred1, y_gen1)\n",
    "\n",
    "# Number of samples\n",
    "num_samples1 = len(y_gen1)\n",
    "\n",
    "acc_pc = pd.DataFrame({\n",
    "    \"Accuracy\": accuracy1, \n",
    "    \"Precision\": precision1, \n",
    "    \"Number of Samples\": num_samples1\n",
    "}, index=[\"CO(GT) classification\"])\n",
    "acc_pc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d315c940",
   "metadata": {},
   "source": [
    "### Regression NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "73a15ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Number of Samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Estimation of NOx(GT)</th>\n",
       "      <td>110.275677</td>\n",
       "      <td>78.084246</td>\n",
       "      <td>872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             RMSE        MAE  Number of Samples\n",
       "Estimation of NOx(GT)  110.275677  78.084246                872"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict target values on test set\n",
    "y_pred2 = model2.predict(X_gen2).flatten()\n",
    "\n",
    "# mse\n",
    "mse2 = mean_squared_error(y_gen2, y_pred2)\n",
    "# root mse\n",
    "rmse2 = mse2 ** 0.5\n",
    "\n",
    "# mae\n",
    "mae2 = mean_absolute_error(y_gen2, y_pred2)\n",
    "\n",
    "num_samples2 = len(y_gen2)\n",
    "\n",
    "rmse_mae = pd.DataFrame({\n",
    "    \"RMSE\": rmse2, \n",
    "    \"MAE\": mae2, \n",
    "    \"Number of Samples\": num_samples2\n",
    "}, index=[\"Estimation of NOx(GT)\"])\n",
    "rmse_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f32926",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
